# Laborario_3: Problema de coctel

Este proyecto aborda el problema del cÃ³ctel, en el cual se busca aislar una voz de interÃ©s a partir de una mezcla de mÃºltiples fuentes sonoras.

Se implementan dos mÃ©todos de separaciÃ³n de seÃ±ales:

âœ” AnÃ¡lisis de Componentes Independientes (ICA) â†’ Para extraer la voz de Laura.

âœ” AnÃ¡lisis de Componentes Principales (PCA) â†’ Para extraer la voz de Andrea.

ğŸ”¹ Frecuencia de muestreo: 44,100 Hz (Apple arroja eso que es nuestro sistema de adquisiciÃ³n).

ğŸ”¹ DuraciÃ³n de las grabaciones: 15 segundos.

ğŸ“Œ Â¿QuÃ© es el Problema del CÃ³ctel?

El Problema del CÃ³ctel es un fenÃ³meno en el que el cerebro humano es capaz de enfocarse en una sola conversaciÃ³n dentro de un ambiente lleno de ruido y mÃºltiples voces.

ğŸ’¡ Ejemplo real:
Imagina que estÃ¡s en una fiesta con muchas personas hablando al mismo tiempo. A pesar del ruido, puedes concentrarte en la voz de tu amigo y entender lo que dice sin que los otros sonidos te distraigan demasiado.

ğŸ“¢ Â¿CÃ³mo se aplica esto en procesamiento de seÃ±ales?

- Queremos que un algoritmo escuche una grabaciÃ³n con varias voces y ruido y sea capaz de separar una voz especÃ­fica de la mezcla.
- Esto es Ãºtil para aplicaciones como:
  - Reconocimiento de voz (Siri, Google Assistant).
  - AudÃ­fonos con cancelaciÃ³n de ruido.
  - AnÃ¡lisis forense de audio.

ğŸ“Œ MÃ©todos utilizados en este laboratorio:

âœ… ICA (AnÃ¡lisis de Componentes Independientes): SeparaciÃ³n de la voz de Laura.

âœ… PCA (AnÃ¡lisis de Componentes Principales): SeparaciÃ³n de la voz de Andrea.

ğŸ“Š Datos de AdquisiciÃ³n y ParÃ¡metros TÃ©cnicos

ğŸ“Œ Fuente de los datos:

Las grabaciones fueron adquiridas con un sistema de Apple, el cual proporciona una frecuencia de muestreo de 44,100 Hz, lo que significa que el audio fue capturado 44,100 veces por segundo.

ğŸ“Œ DuraciÃ³n de los audios:

Cada grabaciÃ³n tiene una duraciÃ³n de 15 segundos.

ğŸ“Œ SeÃ±ales capturadas:

ğŸ¤ Voz 1: Andrea.

ğŸ¤ Voz 2: Laura.

ğŸŒ Ruido ambiental: Captado por otro celular.

![Imagen de WhatsApp 2025-03-03 a las 20 22 55_ba03838e](https://github.com/user-attachments/assets/772f1a1d-51f6-4930-9aed-6cd7ae1c8748)
Fig 1. OrganizaciÃ³n de los microfonos 


ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n
Antes de ejecutar los scripts, instala las dependencias necesarias:

        pip install -r requirements.txt
        
Si no tienes el archivo requirements.txt, instala manualmente:

        pip install numpy matplotlib scipy scikit-learn sounddevice

ğŸ” MÃ©todos de SeparaciÃ³n de Voz

1ï¸âƒ£ MÃ©todo ICA (Independent Component Analysis) â€“ SeparaciÃ³n de la Voz de Laura

ğŸ“Œ Â¿QuÃ© es ICA?

El AnÃ¡lisis de Componentes Independientes (ICA) es un mÃ©todo que permite separar seÃ±ales que han sido mezcladas en un mismo entorno, bajo la suposiciÃ³n de que las seÃ±ales originales son estadÃ­sticamente independientes entre sÃ­.

ğŸ” Ejemplo prÃ¡ctico:

- Imagina que tienes dos micrÃ³fonos en una sala donde estÃ¡n hablando Laura y Andrea.
- Cada micrÃ³fono captarÃ¡ una mezcla de ambas voces con diferente intensidad.
- ICA analizarÃ¡ la seÃ±al e intentarÃ¡ separar las fuentes independientes, recuperando las voces originales.

ğŸ“Œ Pasos realizados en ICA:

âœ”ï¸ Cargamos las seÃ±ales de los micrÃ³fonos.

âœ”ï¸ Aplicamos ICA para extraer las voces.

âœ”ï¸ Guardamos la voz de interÃ©s en un archivo WAV.

âœ”ï¸ Analizamos el espectro de frecuencia antes y despuÃ©s de la separaciÃ³n.

ğŸ“Œ CÃ³digo (fragmento de ICA):

        # Graficar el ruido original
        plt.subplot(3, 2, 5)
        plt.plot(np.arange(len(ruido)) / fs_ruido, ruido, label='Ruido', color='yellow', alpha=0.5)
        plt.title('Ruido Original')
        plt.xlabel('Tiempo (s)')
        plt.ylabel('Amplitud')
        plt.grid(True)
        
        # Calcular la FFT del ruido
        X_ruido = np.abs(np.fft.fft(ruido))
        
        # Graficar el espectro en escala semilogarÃ­tmica para el Ruido
        plt.subplot(3, 2, 6)
        plt.semilogx(freqs[:N//2], X_ruido[:N//2], label='Espectro Ruido', color='yellow')
        plt.title('Espectro de Ruido (Escala SemilogarÃ­tmica)')
        plt.xlabel('Frecuencia (Hz)')
        plt.ylabel('Magnitud')
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # Guardar la voz separada en un archivo WAV
        guardar_audio('VozLauraSeparada_ICA.wav', fs_ruido, voz2_separada)

![ICA-ESPECTRO](https://github.com/user-attachments/assets/4f27dc92-1aa6-4847-acbd-c9e35dae6ff0)
Fig 2. Ica espectro

![ICA-TODAS](https://github.com/user-attachments/assets/768700c2-46b8-43f8-bed6-684bfe4ee758)
Fig 3. Ica todas

2ï¸âƒ£ MÃ©todo PCA (Principal Component Analysis) â€“ SeparaciÃ³n de la Voz de Andrea

ğŸ“Œ Â¿QuÃ© es PCA?

El AnÃ¡lisis de Componentes Principales (PCA) es un mÃ©todo matemÃ¡tico utilizado para reducir la dimensionalidad de los datos sin perder informaciÃ³n relevante. En este caso, lo usamos para separar las voces mezcladas con el ruido.

ğŸ“Œ Diferencias entre PCA e ICA:

- ICA intenta separar seÃ±ales independientes entre sÃ­.
- PCA encuentra las direcciones de mayor variabilidad en los datos, lo que permite distinguir mejor cada seÃ±al.
  
ğŸ“Œ Pasos realizados en PCA:

âœ”ï¸ Carga y normalizaciÃ³n de las seÃ±ales de audio.

âœ”ï¸ Asegurar que todas las seÃ±ales tengan la misma duraciÃ³n.

âœ”ï¸ Aumentar la amplitud de las seÃ±ales de voz para mejorar la relaciÃ³n seÃ±al-ruido (SNR).

âœ”ï¸ Combinar las seÃ±ales de voz con el ruido ambiental.

âœ”ï¸ Calcular el SNR antes y despuÃ©s de la separaciÃ³n.

âœ”ï¸ Aplicar PCA para extraer las voces.

âœ”ï¸ Guardar las voces separadas en archivos WAV.

âœ”ï¸ Graficar las seÃ±ales separadas y sus espectros de frecuencia.

ğŸ“Œ CÃ³digo (fragmento de PCA):

        import numpy as np
        import scipy.io.wavfile as wavfile
        import matplotlib.pyplot as plt
        from sklearn.decomposition import PCA
        import sounddevice as sd  # LibrerÃ­a para reproducir audio
        
        # FunciÃ³n para cargar y normalizar seÃ±ales
        def cargar_y_normalizar_audio(archivo):
            fs, seÃ±al = wavfile.read(archivo)
            # Normalizar la seÃ±al
            seÃ±al = seÃ±al.astype(np.float32) / np.max(np.abs(seÃ±al))
            return fs, seÃ±al
        
        # Cargar las seÃ±ales de audio
        fs_ruido, ruido = cargar_y_normalizar_audio('RuidoAmbiente.wav')
        fs_voz1, voz1 = cargar_y_normalizar_audio('VozAndrea.wav')
        fs_voz2, voz2 = cargar_y_normalizar_audio('VozLaura.wav')
        
        # Asegurar que todas las seÃ±ales tengan la misma longitud
        min_length = min(len(ruido), len(voz1), len(voz2))
        ruido = ruido[:min_length]
        voz1 = voz1[:min_length]
        voz2 = voz2[:min_length]
        
        # Aumentar la amplitud de las seÃ±ales de voz para mejorar el SNR
        factor_ganancia = 10  # Ajusta este valor segÃºn sea necesario
        voz1_amplificada = voz1 * factor_ganancia
        voz2_amplificada = voz2 * factor_ganancia
        
        # Crear una seÃ±al combinada de las voces sobre el ruido
        combinado_voz1 = ruido + voz1_amplificada
        combinado_voz2 = ruido + voz2_amplificada
        
        # FunciÃ³n para calcular la relaciÃ³n seÃ±al a ruido (SNR)
        def calcular_snr(seÃ±al_original, seÃ±al_combinada):
            ruido = seÃ±al_combinada - seÃ±al_original
            potencia_seÃ±al = np.var(seÃ±al_original)
            potencia_ruido = np.var(ruido)
            snr = 10 * np.log10(potencia_seÃ±al / potencia_ruido)
            return snr
        
        # Calcular SNR para Voz Andrea y Voz Laura
        snr_voz1 = calcular_snr(voz1_amplificada, combinado_voz1)
        snr_voz2 = calcular_snr(voz2_amplificada, combinado_voz2)
        # Mostrar los valores de SNR
        print(f"SNR Voz Andrea sobre Ruido: {snr_voz1:.2f} dB")
        print(f"SNR Voz Laura sobre Ruido: {snr_voz2:.2f} dB")
        
        # Graficar las seÃ±ales combinadas
        plt.figure(figsize=(10, 6))
        tiempo = np.arange(len(ruido)) / fs_ruido
        
        plt.plot(tiempo, combinado_voz1, label='Voz Andrea sobre Ruido', color='orange', alpha=0.7)
        plt.plot(tiempo, combinado_voz2, label='Voz Laura sobre Ruido', color='pink', alpha=0.7)
        plt.plot(tiempo, ruido, label='Ruido', color='yellow', alpha=0.5)
        
        plt.title('SeÃ±ales combinadas')
        plt.xlabel('Tiempo (s)')
        plt.ylabel('Amplitud')
        plt.legend()
        plt.grid(True)
        plt.show()
        
        # Apilar las seÃ±ales en una matriz de 2 filas (una para cada mezcla) 
        X = np.c_[combinado_voz1, combinado_voz2]  # AquÃ­ las mezclas se apilan en columnas
        
        # Aplicar PCA para separar las seÃ±ales
        pca = PCA(n_components=2)  # Queremos separar 2 seÃ±ales
        X_separadas = pca.fit_transform(X)  # Esto te da las seÃ±ales separadas
        
        # Recuperar las seÃ±ales separadas
        voz1_separada = X_separadas[:, 0]
        voz2_separada = X_separadas[:, 1]
        
        # Guardar las seÃ±ales separadas como archivos WAV
        def guardar_audio(archivo, fs, seÃ±al):
            seÃ±al = np.int16(seÃ±al * 32767)  # Convertir de vuelta a 16-bit PCM
            wavfile.write(archivo, fs, seÃ±al)
        
        guardar_audio('VozAndreaSeparada_PCA.wav', fs_ruido, voz1_separada)
        guardar_audio('VozLauraSeparada_PCA.wav', fs_ruido, voz2_separada)
        
        # Reproducir la Voz de Andrea
        sd.play(voz1_separada, fs_ruido)  # Reproduce la seÃ±al separada de Voz Andrea
        sd.wait()  # Espera a que termine la reproducciÃ³n

![PSA-ESPECTRO](https://github.com/user-attachments/assets/d3228fab-2cd0-48d5-afac-30651b8f35fb)
Fig 4. PCA espectro

![PCA-TODAS](https://github.com/user-attachments/assets/17233842-397c-4eab-8230-da00f576c101)
Fig 5. PCA todas


ğŸ“ˆ Resultados y AnÃ¡lisis 

DespuÃ©s de aplicar los mÃ©todos ICA y PCA para separar las voces de Andrea y Laura en un ambiente ruidoso, se realizaron diversas evaluaciones para comparar la efectividad de cada tÃ©cnica.

 1ï¸âƒ£ ComparaciÃ³n de MÃ©todos

 - ICA logra una mejor separaciÃ³n de la voz de Laura, ya que se basa en la independencia estadÃ­stica de las fuentes de sonido.
 - PCA funciona bien, pero no es tan efectivo en este contexto, ya que la correlaciÃ³n entre las seÃ±ales de voz y ruido no es lo suficientemente fuerte para lograr una separaciÃ³n Ã³ptima.

2ï¸âƒ£ AnÃ¡lisis de la RelaciÃ³n SeÃ±al/Ruido (SNR)

ğŸ“Œ DefiniciÃ³n de SNR:

El SNR (Signal-to-Noise Ratio) mide quÃ© tan fuerte es la seÃ±al deseada en comparaciÃ³n con el ruido. Se expresa en decibeles (dB) y se calcula como:

![{F4CFC1C5-5424-4002-A313-1D0534AD347A}](https://github.com/user-attachments/assets/01b0d82b-bc20-4c1c-8851-dd19a90f652f)

Fig 6. FÃ³rmula del SNR

ğŸ“Œ Valores obtenidos:

- ICA	5 - 7 dB (mala calidad)	22 - 25 dB (alta calidad)
- PCA	5 - 7 dB (mala calidad)	15 - 18 dB (calidad moderada)

ğŸ“Œ AnÃ¡lisis de estos valores:

âœ”ï¸ ICA aumenta drÃ¡sticamente el SNR, permitiendo obtener una voz clara con mÃ­nimo ruido residual.

âœ”ï¸ PCA tambiÃ©n mejora el SNR, pero al no estar diseÃ±ado especÃ­ficamente para separar seÃ±ales de audio, deja algo de ruido en la voz recuperada.

ğŸ“Œ VisualizaciÃ³n del SNR en grÃ¡ficos:

        # Graficar la mejora del SNR
        etiquetas = ['Antes de separaciÃ³n', 'DespuÃ©s de ICA', 'DespuÃ©s de PCA']
        valores = [5, 23, 17]  # Ejemplo de SNR en dB
        
        plt.figure(figsize=(8,5))
        plt.bar(etiquetas, valores, color=['red', 'green', 'blue'])
        plt.xlabel('MÃ©todo')
        plt.ylabel('SNR (dB)')
        plt.title('ComparaciÃ³n de SNR antes y despuÃ©s de la separaciÃ³n de voces')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        plt.show()

ğŸ“· Evidencia de la EjecuciÃ³n en Consola

AquÃ­ se muestran los valores de SNR obtenidos al ejecutar los mÃ©todos de separaciÃ³n de voz:

![Imagen de WhatsApp 2025-03-01 a las 13 24 56_bbfc5c3d](https://github.com/user-attachments/assets/644d3fca-2211-4b80-ac9f-e5038a866a60)

Fig 7. SNR de Ica

![Imagen de WhatsApp 2025-03-01 a las 13 25 15_69f82c20](https://github.com/user-attachments/assets/7907cfa4-c7ef-4baf-a163-be2c4fda7d78)

Fig 8. SNR de PCA

3ï¸âƒ£ AnÃ¡lisis Espectral de las SeÃ±ales Separadas

ğŸ“Œ Â¿QuÃ© analizamos aquÃ­?

Al calcular la Transformada RÃ¡pida de Fourier (FFT), podemos ver el contenido de frecuencia de las seÃ±ales antes y despuÃ©s de la separaciÃ³n.

ğŸ“Œ Observaciones en los espectros:

- El espectro de la seÃ±al original muestra picos en diferentes frecuencias debido a la mezcla de voces.
- DespuÃ©s de ICA, el espectro de la voz de Laura es mÃ¡s limpio, eliminando frecuencias innecesarias.
- DespuÃ©s de PCA, el espectro de Andrea todavÃ­a tiene algunas interferencias del ruido original.

ğŸ“„ ConclusiÃ³n

âœ… ICA es ideal cuando las seÃ±ales son independientes entre sÃ­.

âœ… PCA es Ãºtil cuando las seÃ±ales tienen cierto grado de correlaciÃ³n.

âœ… La posiciÃ³n de los micrÃ³fonos y la calidad de la adquisiciÃ³n afectan significativamente los resultados.
